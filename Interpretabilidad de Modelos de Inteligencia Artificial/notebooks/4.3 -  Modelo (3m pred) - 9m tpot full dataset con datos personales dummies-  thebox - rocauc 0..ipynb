{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from tpot import TPOTClassifier\n",
    "import xgboost as xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set() #adoptando el estilo de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 842516 entries, 0 to 842515\n",
      "Data columns (total 62 columns):\n",
      "9 meses                           842516 non-null float64\n",
      "8 meses                           842516 non-null float64\n",
      "7 meses                           842516 non-null float64\n",
      "6 meses                           842516 non-null float64\n",
      "5 meses                           842516 non-null float64\n",
      "4 meses                           842516 non-null float64\n",
      "edad                              827773 non-null float64\n",
      "GENDER_F                          842516 non-null int64\n",
      "GENDER_M                          842516 non-null int64\n",
      "MARITAL_STATUS_Casado             842516 non-null int64\n",
      "MARITAL_STATUS_Conviv             842516 non-null int64\n",
      "MARITAL_STATUS_Divorciado         842516 non-null int64\n",
      "MARITAL_STATUS_No Corresp         842516 non-null int64\n",
      "MARITAL_STATUS_Separado           842516 non-null int64\n",
      "MARITAL_STATUS_Soltero            842516 non-null int64\n",
      "MARITAL_STATUS_Union Civ          842516 non-null int64\n",
      "MARITAL_STATUS_Viudo              842516 non-null int64\n",
      "EDUCATION_N                       842516 non-null int64\n",
      "EDUCATION_S                       842516 non-null int64\n",
      "EDUCATION_LEVEL_PRIMARIO          842516 non-null int64\n",
      "EDUCATION_LEVEL_SECUNDARIO        842516 non-null int64\n",
      "EDUCATION_LEVEL_TERCIARIO         842516 non-null int64\n",
      "EDUCATION_LEVEL_UNIVERSITARIO     842516 non-null int64\n",
      "CITY_ANTARTIDA E ISLAS DEL SUR    842516 non-null int64\n",
      "CITY_BUENOS AIRES                 842516 non-null int64\n",
      "CITY_CAPITAL FEDERAL              842516 non-null int64\n",
      "CITY_CATAMARCA                    842516 non-null int64\n",
      "CITY_CHACO                        842516 non-null int64\n",
      "CITY_CHUBUT                       842516 non-null int64\n",
      "CITY_CORDOBA                      842516 non-null int64\n",
      "CITY_CORRIENTES                   842516 non-null int64\n",
      "CITY_ENTRE RIOS                   842516 non-null int64\n",
      "CITY_FORMOSA                      842516 non-null int64\n",
      "CITY_JUJUY                        842516 non-null int64\n",
      "CITY_LA PAMPA                     842516 non-null int64\n",
      "CITY_LA RIOJA                     842516 non-null int64\n",
      "CITY_MENDOZA                      842516 non-null int64\n",
      "CITY_MISIONES                     842516 non-null int64\n",
      "CITY_NEUQUEN                      842516 non-null int64\n",
      "CITY_RIO NEGRO                    842516 non-null int64\n",
      "CITY_SALTA                        842516 non-null int64\n",
      "CITY_SAN JUAN                     842516 non-null int64\n",
      "CITY_SAN LUIS                     842516 non-null int64\n",
      "CITY_SANTA CRUZ                   842516 non-null int64\n",
      "CITY_SANTA FE                     842516 non-null int64\n",
      "CITY_SANTIAGO DEL ESTERO          842516 non-null int64\n",
      "CITY_TIERRA DEL FUEGO             842516 non-null int64\n",
      "CITY_TUCUMAN                      842516 non-null int64\n",
      "ModoPago_BA                       842516 non-null int64\n",
      "ModoPago_CC                       842516 non-null int64\n",
      "ModoPago_Mix                      842516 non-null int64\n",
      "ModoPago_PP                       842516 non-null int64\n",
      "ModoPago_SJ                       842516 non-null int64\n",
      "ModoPago_TA                       842516 non-null int64\n",
      "ModoPago_TM                       842516 non-null int64\n",
      "CUSTOMER_ID                       842516 non-null int64\n",
      "Churn                             842516 non-null int64\n",
      "3 meses                           842516 non-null float64\n",
      "2 meses                           842516 non-null float64\n",
      "1 meses                           842516 non-null float64\n",
      "LOCALITY                          645413 non-null object\n",
      "OCCUPATION                        514756 non-null object\n",
      "dtypes: float64(10), int64(50), object(2)\n",
      "memory usage: 398.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/9m churn con datos pers dummies.csv\")\n",
    "df = df.iloc[:,1:]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-7]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"edad\"].hist()\n",
    "X.drop(\"edad\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 842516 entries, 0 to 842515\n",
      "Data columns (total 54 columns):\n",
      "9 meses                           842516 non-null int32\n",
      "8 meses                           842516 non-null int32\n",
      "7 meses                           842516 non-null int32\n",
      "6 meses                           842516 non-null int32\n",
      "5 meses                           842516 non-null int32\n",
      "4 meses                           842516 non-null int32\n",
      "GENDER_F                          842516 non-null int32\n",
      "GENDER_M                          842516 non-null int32\n",
      "MARITAL_STATUS_Casado             842516 non-null int32\n",
      "MARITAL_STATUS_Conviv             842516 non-null int32\n",
      "MARITAL_STATUS_Divorciado         842516 non-null int32\n",
      "MARITAL_STATUS_No Corresp         842516 non-null int32\n",
      "MARITAL_STATUS_Separado           842516 non-null int32\n",
      "MARITAL_STATUS_Soltero            842516 non-null int32\n",
      "MARITAL_STATUS_Union Civ          842516 non-null int32\n",
      "MARITAL_STATUS_Viudo              842516 non-null int32\n",
      "EDUCATION_N                       842516 non-null int32\n",
      "EDUCATION_S                       842516 non-null int32\n",
      "EDUCATION_LEVEL_PRIMARIO          842516 non-null int32\n",
      "EDUCATION_LEVEL_SECUNDARIO        842516 non-null int32\n",
      "EDUCATION_LEVEL_TERCIARIO         842516 non-null int32\n",
      "EDUCATION_LEVEL_UNIVERSITARIO     842516 non-null int32\n",
      "CITY_ANTARTIDA E ISLAS DEL SUR    842516 non-null int32\n",
      "CITY_BUENOS AIRES                 842516 non-null int32\n",
      "CITY_CAPITAL FEDERAL              842516 non-null int32\n",
      "CITY_CATAMARCA                    842516 non-null int32\n",
      "CITY_CHACO                        842516 non-null int32\n",
      "CITY_CHUBUT                       842516 non-null int32\n",
      "CITY_CORDOBA                      842516 non-null int32\n",
      "CITY_CORRIENTES                   842516 non-null int32\n",
      "CITY_ENTRE RIOS                   842516 non-null int32\n",
      "CITY_FORMOSA                      842516 non-null int32\n",
      "CITY_JUJUY                        842516 non-null int32\n",
      "CITY_LA PAMPA                     842516 non-null int32\n",
      "CITY_LA RIOJA                     842516 non-null int32\n",
      "CITY_MENDOZA                      842516 non-null int32\n",
      "CITY_MISIONES                     842516 non-null int32\n",
      "CITY_NEUQUEN                      842516 non-null int32\n",
      "CITY_RIO NEGRO                    842516 non-null int32\n",
      "CITY_SALTA                        842516 non-null int32\n",
      "CITY_SAN JUAN                     842516 non-null int32\n",
      "CITY_SAN LUIS                     842516 non-null int32\n",
      "CITY_SANTA CRUZ                   842516 non-null int32\n",
      "CITY_SANTA FE                     842516 non-null int32\n",
      "CITY_SANTIAGO DEL ESTERO          842516 non-null int32\n",
      "CITY_TIERRA DEL FUEGO             842516 non-null int32\n",
      "CITY_TUCUMAN                      842516 non-null int32\n",
      "ModoPago_BA                       842516 non-null int32\n",
      "ModoPago_CC                       842516 non-null int32\n",
      "ModoPago_Mix                      842516 non-null int32\n",
      "ModoPago_PP                       842516 non-null int32\n",
      "ModoPago_SJ                       842516 non-null int32\n",
      "ModoPago_TA                       842516 non-null int32\n",
      "ModoPago_TM                       842516 non-null int32\n",
      "dtypes: int32(54)\n",
      "memory usage: 173.6 MB\n"
     ]
    }
   ],
   "source": [
    "X = X.astype(\"int32\")\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separo la bd train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SIZE=0.20\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 674012 - test: 168504\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {} - test: {}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.naive_bayes.GaussianNB': {}, 'sklearn.naive_bayes.BernoulliNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.naive_bayes.MultinomialNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.tree.DecisionT....3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])}}}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "        early_stop=None, generations=1000000, max_eval_time_mins=5,\n",
       "        max_time_mins=100, memory=None, mutation_rate=0.9, n_jobs=8,\n",
       "        offspring_size=20, periodic_checkpoint_folder=None,\n",
       "        population_size=20, random_state=42, scoring=None, subsample=1.0,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, random_state=RANDOM_STATE, verbosity=2, max_time_mins=100, n_jobs=-1, scoring=\"roc_auc\")\n",
    "tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\stopit\\utils.py\", line 145, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py\", line 426, in _wrapped_cross_val_score\n    cv = check_cv(cv, target, classifier=is_classifier(sklearn_pipeline))\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 1905, in check_cv\n    (type_of_target(y) in ('binary', 'multiclass'))):\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 288, in type_of_target\n    if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 223, in unique\n    return _unique1d(ar, return_index, return_inverse, return_counts)\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 283, in _unique1d\n    ar.sort()\nTypeError: '<' not supported between instances of 'float' and 'str'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Mon Sep  3 16:19:12 2018\nPID: 3808                 Python 3.6.5: C:\\Users\\Admin\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300), (), {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300)\n        args = ()\n        kwargs = {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\stopit\\utils.py in wrapper(*args=(), **kwargs={'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)})\n    140             timeout = kwargs.pop(self.timeout_param, None)\n    141             if timeout:\n    142                 with self.to_ctx_mgr(timeout, swallow_exc=True):\n    143                     result = self.default  # noqa\n    144                     # ``result`` may not be assigned below in case of timeout\n--> 145                     result = func(*args, **kwargs)\n        result = 'Timeout'\n        args = ()\n        kwargs = {'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)}\n    146                 return result\n    147             else:\n    148                 return func(*args, **kwargs)\n    149         return wrapper\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py in _wrapped_cross_val_score(sklearn_pipeline=Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), features=memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), target=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), cv=5, scoring_function='roc_auc', sample_weight=None, groups=None)\n    421     \"\"\"\n    422     sample_weight_dict = set_sample_weight(sklearn_pipeline.steps, sample_weight)\n    423 \n    424     features, target, groups = indexable(features, target, groups)\n    425 \n--> 426     cv = check_cv(cv, target, classifier=is_classifier(sklearn_pipeline))\n        cv = 5\n        target = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        sklearn_pipeline = Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])\n    427     cv_iter = list(cv.split(features, target, groups))\n    428     scorer = check_scoring(sklearn_pipeline, scoring=scoring_function)\n    429 \n    430     try:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py in check_cv(cv=5, y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), classifier=True)\n   1900     if cv is None:\n   1901         cv = 3\n   1902 \n   1903     if isinstance(cv, numbers.Integral):\n   1904         if (classifier and (y is not None) and\n-> 1905                 (type_of_target(y) in ('binary', 'multiclass'))):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n   1906             return StratifiedKFold(cv)\n   1907         else:\n   1908             return KFold(cv)\n   1909 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py in type_of_target(y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object))\n    283     # check float and contains non-integer float values\n    284     if y.dtype.kind == 'f' and np.any(y != y.astype(int)):\n    285         # [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\n    286         return 'continuous' + suffix\n    287 \n--> 288     if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        y.ndim = 1\n    289         return 'multiclass' + suffix  # [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\n    290     else:\n    291         return 'binary'  # [1, 2] or [[\"a\"], [\"b\"]]\n    292 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in unique(ar=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False, axis=None)\n    218     array([1, 2, 6, 4, 2, 3, 2])\n    219 \n    220     \"\"\"\n    221     ar = np.asanyarray(ar)\n    222     if axis is None:\n--> 223         return _unique1d(ar, return_index, return_inverse, return_counts)\n        ar = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        return_index = False\n        return_inverse = False\n        return_counts = False\n    224     if not (-ar.ndim <= axis < ar.ndim):\n    225         raise ValueError('Invalid axis kwarg specified for unique')\n    226 \n    227     ar = np.swapaxes(ar, axis, 0)\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in _unique1d(ar=array(['ADNI', nan, 'MEDI', ..., nan, 'EMPL', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False)\n    278 \n    279     if optional_indices:\n    280         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n    281         aux = ar[perm]\n    282     else:\n--> 283         ar.sort()\n        ar.sort = <built-in method sort of numpy.ndarray object>\n    284         aux = ar\n    285     flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n    286 \n    287     if not optional_returns:\n\nTypeError: '<' not supported between instances of 'float' and 'str'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Mon Sep  3 16:19:12 2018\nPID: 3808                 Python 3.6.5: C:\\Users\\Admin\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300), (), {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300)\n        args = ()\n        kwargs = {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\stopit\\utils.py in wrapper(*args=(), **kwargs={'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)})\n    140             timeout = kwargs.pop(self.timeout_param, None)\n    141             if timeout:\n    142                 with self.to_ctx_mgr(timeout, swallow_exc=True):\n    143                     result = self.default  # noqa\n    144                     # ``result`` may not be assigned below in case of timeout\n--> 145                     result = func(*args, **kwargs)\n        result = 'Timeout'\n        args = ()\n        kwargs = {'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)}\n    146                 return result\n    147             else:\n    148                 return func(*args, **kwargs)\n    149         return wrapper\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py in _wrapped_cross_val_score(sklearn_pipeline=Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), features=memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), target=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), cv=5, scoring_function='roc_auc', sample_weight=None, groups=None)\n    421     \"\"\"\n    422     sample_weight_dict = set_sample_weight(sklearn_pipeline.steps, sample_weight)\n    423 \n    424     features, target, groups = indexable(features, target, groups)\n    425 \n--> 426     cv = check_cv(cv, target, classifier=is_classifier(sklearn_pipeline))\n        cv = 5\n        target = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        sklearn_pipeline = Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])\n    427     cv_iter = list(cv.split(features, target, groups))\n    428     scorer = check_scoring(sklearn_pipeline, scoring=scoring_function)\n    429 \n    430     try:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py in check_cv(cv=5, y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), classifier=True)\n   1900     if cv is None:\n   1901         cv = 3\n   1902 \n   1903     if isinstance(cv, numbers.Integral):\n   1904         if (classifier and (y is not None) and\n-> 1905                 (type_of_target(y) in ('binary', 'multiclass'))):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n   1906             return StratifiedKFold(cv)\n   1907         else:\n   1908             return KFold(cv)\n   1909 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py in type_of_target(y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object))\n    283     # check float and contains non-integer float values\n    284     if y.dtype.kind == 'f' and np.any(y != y.astype(int)):\n    285         # [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\n    286         return 'continuous' + suffix\n    287 \n--> 288     if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        y.ndim = 1\n    289         return 'multiclass' + suffix  # [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\n    290     else:\n    291         return 'binary'  # [1, 2] or [[\"a\"], [\"b\"]]\n    292 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in unique(ar=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False, axis=None)\n    218     array([1, 2, 6, 4, 2, 3, 2])\n    219 \n    220     \"\"\"\n    221     ar = np.asanyarray(ar)\n    222     if axis is None:\n--> 223         return _unique1d(ar, return_index, return_inverse, return_counts)\n        ar = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        return_index = False\n        return_inverse = False\n        return_counts = False\n    224     if not (-ar.ndim <= axis < ar.ndim):\n    225         raise ValueError('Invalid axis kwarg specified for unique')\n    226 \n    227     ar = np.swapaxes(ar, axis, 0)\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in _unique1d(ar=array(['ADNI', nan, 'MEDI', ..., nan, 'EMPL', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False)\n    278 \n    279     if optional_indices:\n    280         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n    281         aux = ar[perm]\n    282     else:\n--> 283         ar.sort()\n        ar.sort = <built-in method sort of numpy.ndarray object>\n    284         aux = ar\n    285     flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n    286 \n    287     if not optional_returns:\n\nTypeError: '<' not supported between instances of 'float' and 'str'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                     \u001b[0mper_generation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_periodic_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[1;34m(self, individuals, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                 tmp_result_scores = parallel(delayed(partial_wrapped_cross_val_score)(sklearn_pipeline=sklearn_pipeline)\n\u001b[1;32m-> 1172\u001b[1;33m                                              for sklearn_pipeline in sklearn_pipeline_list[chunk_idx:chunk_idx + chunk_size])\n\u001b[0m\u001b[0;32m   1173\u001b[0m                 \u001b[1;31m# update pbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000254FD344150, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000254FD344150, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(452, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(452, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (452, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=452, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 3, 19, 19, 3, 170101, tzinfo=tzutc()), 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'session': '209307c229364d53b3dfe208f3b8a36f', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'209307c229364d53b3dfe208f3b8a36f']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 3, 19, 19, 3, 170101, tzinfo=tzutc()), 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'session': '209307c229364d53b3dfe208f3b8a36f', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'209307c229364d53b3dfe208f3b8a36f'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 3, 19, 19, 3, 170101, tzinfo=tzutc()), 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'session': '209307c229364d53b3dfe208f3b8a36f', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6944181123454170a5fd74e42a13128e', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-45-2da0da1324f1>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 254857aff60, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000254823FDA50, file \"<ipython-input-45-2da0da1324f1>\", line 1>\n        result = <ExecutionResult object at 254857aff60, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000254823FDA50, file \"<ipython-input-45-2da0da1324f1>\", line 1>, result=<ExecutionResult object at 254857aff60, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000254823FDA50, file \"<ipython-input-45-2da0da1324f1>\", line 1>\n        self.user_global_ns = {'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...nline')\\nsns.set() #adoptando el estilo de seaborn\", 'df = pd.read_csv(\"../data/interim/9m churn.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', 'df = pd.read_csv(\"../data/interim/9m churn con datos pers.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', \"import pandas as pd\\nimport numpy as np\\nimport ma...nline')\\nsns.set() #adoptando el estilo de seaborn\", 'df = pd.read_csv(\"../data/interim/9m churn con datos pers dummies.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', '#separo la bd train, test\\nfrom sklearn.model_sel...t train_test_split\\nTEST_SIZE=0.20\\nRANDOM_STATE=42', 'X_train, X_test, y_train, y_test = train_test_sp..., test_size=TEST_SIZE, random_state=RANDOM_STATE)', 'X = df.iloc[:, :-6]\\ny = df.iloc[:,-1]', 'X.head()', 'X = df.iloc[:, :-7]\\ny = df.iloc[:,-1]', 'X.head()', 'X_train, X_test, y_train, y_test = train_test_sp..., test_size=TEST_SIZE, random_state=RANDOM_STATE)', 'print(\"train: {} - test: {}\".format(len(X_train), len(X_test)))', 'from sklearn.metrics import roc_auc_score\\n\\ntpot ...time_mins=100, n_jobs=-1, scoring=\"roc_auc\")\\ntpot', 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', 'X.info()', 'X.astype(int)\\nX.info()', 'X.isna()', 'X.isna().sum(axis=1)', ...], 'Out': {9:    9 meses  8 meses  7 meses  6 meses  5 meses  ...          0        17153  \n\n[5 rows x 56 columns], 11:    9 meses  8 meses  7 meses  6 meses  5 meses  ...          0            0  \n\n[5 rows x 55 columns], 14: TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), 18:         9 meses  8 meses  7 meses  6 meses  5 me... False        False  \n\n[842516 rows x 55 columns], 19: 0         0\n1         0\n2         0\n3         0\n...514    0\n842515    0\nLength: 842516, dtype: int64, 20: 9 meses                               0\n8 meses ...oPago_TM                           0\ndtype: int64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: 118.0    40505\n38.0     20859\n40.0     20463\n39.....0        8\nName: edad, Length: 102, dtype: int64, 23: <matplotlib.axes._subplots.AxesSubplot object>, 24: <matplotlib.axes._subplots.AxesSubplot object>, ...}, 'RANDOM_STATE': 42, 'TEST_SIZE': 0.2, 'TPOTClassifier': <class 'tpot.tpot.TPOTClassifier'>, 'X':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[842516 rows x 54 columns], 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[168504 rows x 54 columns], 'X_train':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[674012 rows x 54 columns], '_': TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), ...}\n        self.user_ns = {'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...nline')\\nsns.set() #adoptando el estilo de seaborn\", 'df = pd.read_csv(\"../data/interim/9m churn.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', 'df = pd.read_csv(\"../data/interim/9m churn con datos pers.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', \"import pandas as pd\\nimport numpy as np\\nimport ma...nline')\\nsns.set() #adoptando el estilo de seaborn\", 'df = pd.read_csv(\"../data/interim/9m churn con datos pers dummies.csv\")\\ndf = df.iloc[:,1:]\\ndf.info()', '#separo la bd train, test\\nfrom sklearn.model_sel...t train_test_split\\nTEST_SIZE=0.20\\nRANDOM_STATE=42', 'X_train, X_test, y_train, y_test = train_test_sp..., test_size=TEST_SIZE, random_state=RANDOM_STATE)', 'X = df.iloc[:, :-6]\\ny = df.iloc[:,-1]', 'X.head()', 'X = df.iloc[:, :-7]\\ny = df.iloc[:,-1]', 'X.head()', 'X_train, X_test, y_train, y_test = train_test_sp..., test_size=TEST_SIZE, random_state=RANDOM_STATE)', 'print(\"train: {} - test: {}\".format(len(X_train), len(X_test)))', 'from sklearn.metrics import roc_auc_score\\n\\ntpot ...time_mins=100, n_jobs=-1, scoring=\"roc_auc\")\\ntpot', 'tpot.fit(X_train, y_train)\\nprint(tpot.score(X_test, y_test))', 'X.info()', 'X.astype(int)\\nX.info()', 'X.isna()', 'X.isna().sum(axis=1)', ...], 'Out': {9:    9 meses  8 meses  7 meses  6 meses  5 meses  ...          0        17153  \n\n[5 rows x 56 columns], 11:    9 meses  8 meses  7 meses  6 meses  5 meses  ...          0            0  \n\n[5 rows x 55 columns], 14: TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), 18:         9 meses  8 meses  7 meses  6 meses  5 me... False        False  \n\n[842516 rows x 55 columns], 19: 0         0\n1         0\n2         0\n3         0\n...514    0\n842515    0\nLength: 842516, dtype: int64, 20: 9 meses                               0\n8 meses ...oPago_TM                           0\ndtype: int64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: 118.0    40505\n38.0     20859\n40.0     20463\n39.....0        8\nName: edad, Length: 102, dtype: int64, 23: <matplotlib.axes._subplots.AxesSubplot object>, 24: <matplotlib.axes._subplots.AxesSubplot object>, ...}, 'RANDOM_STATE': 42, 'TEST_SIZE': 0.2, 'TPOTClassifier': <class 'tpot.tpot.TPOTClassifier'>, 'X':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[842516 rows x 54 columns], 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[168504 rows x 54 columns], 'X_train':         9 meses  8 meses  7 meses  6 meses  5 me...     0            0  \n\n[674012 rows x 54 columns], '_': TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Admin\\Documents\\Projects\\LaCaja\\1.1 - Control con f bajas\\notebooks\\<ipython-input-45-2da0da1324f1> in <module>()\n----> 1 tpot.fit(X_train, y_train)\n      2 print(tpot.score(X_test, y_test))\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\base.py in fit(self=TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), features=array([[1., 1., 1., ..., 0., 0., 0.],\n       [1...., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.]]), target=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), sample_weight=None, groups=None)\n    613                     mutpb=self.mutation_rate,\n    614                     ngen=self.generations,\n    615                     pbar=self._pbar,\n    616                     halloffame=self._pareto_front,\n    617                     verbose=self.verbosity,\n--> 618                     per_generation_function=self._check_periodic_pipeline\n        self._check_periodic_pipeline = <bound method TPOTBase._check_periodic_pipeline ...mple=1.0,\n        verbosity=2, warm_start=False)>\n    619                 )\n    620 \n    621             # store population for the next call\n    622             if self.warm_start:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py in eaMuPlusLambda(population=[[<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F2D0>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79828>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79678>], [<deap.gp.Primitive object at 0x0000025485897C28>, <deap.gp.Terminal object at 0x0000025485A675E8>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86E10>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F438>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92360>], [<deap.gp.Primitive object at 0x0000025485897E08... <deap.gp.Terminal object at 0x0000025485A8D558>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92510>], [<deap.gp.Primitive object at 0x0000025485897318... <deap.gp.Terminal object at 0x0000025485A8C168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x00000254858975E8... <deap.gp.Terminal object at 0x0000025485A86E58>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92708>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79900>]], toolbox=<deap.base.Toolbox object>, mu=20, lambda_=20, cxpb=0.1, mutpb=0.9, ngen=1000000, pbar=Optimization Progress:   0%|                    ...                    | 0/20 [00:11<?, ?pipeline/s], stats=None, halloffame=<deap.tools.support.ParetoFront object>, verbose=2, per_generation_function=<bound method TPOTBase._check_periodic_pipeline ...mple=1.0,\n        verbosity=2, warm_start=False)>)\n    225         initialize_stats_dict(ind)\n    226 \n    227     # Evaluate the individuals with an invalid fitness\n    228     invalid_ind = [ind for ind in population if not ind.fitness.valid]\n    229 \n--> 230     fitnesses = toolbox.evaluate(invalid_ind)\n        fitnesses = undefined\n        toolbox.evaluate = functools.partial(<bound method TPOTBase._evalua..., dtype=object), sample_weight=None, groups=None)\n        invalid_ind = [[<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F2D0>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79828>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79678>], [<deap.gp.Primitive object at 0x0000025485897C28>, <deap.gp.Terminal object at 0x0000025485A675E8>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86E10>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F438>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92360>], [<deap.gp.Primitive object at 0x0000025485897E08... <deap.gp.Terminal object at 0x0000025485A8D558>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92510>], [<deap.gp.Primitive object at 0x0000025485897318... <deap.gp.Terminal object at 0x0000025485A8C168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x00000254858975E8... <deap.gp.Terminal object at 0x0000025485A86E58>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92708>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79900>]]\n    231     for ind, fit in zip(invalid_ind, fitnesses):\n    232         ind.fitness.values = fit\n    233 \n    234     if halloffame is not None:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\base.py in _evaluate_individuals(self=TPOTClassifier(config_dict={'sklearn.naive_bayes...ample=1.0,\n        verbosity=2, warm_start=False), individuals=[[<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F2D0>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86DC8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79828>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79678>], [<deap.gp.Primitive object at 0x0000025485897C28>, <deap.gp.Terminal object at 0x0000025485A675E8>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897EF8... <deap.gp.Terminal object at 0x0000025485A86E10>], [<deap.gp.Primitive object at 0x0000025485897138... <deap.gp.Terminal object at 0x0000025485A8F438>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92360>], [<deap.gp.Primitive object at 0x0000025485897E08... <deap.gp.Terminal object at 0x0000025485A8D558>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92510>], [<deap.gp.Primitive object at 0x0000025485897318... <deap.gp.Terminal object at 0x0000025485A8C168>], [<deap.gp.Primitive object at 0x0000025485925098... <deap.gp.Terminal object at 0x0000025485A7CCA8>], [<deap.gp.Primitive object at 0x00000254858975E8... <deap.gp.Terminal object at 0x0000025485A86E58>], [<deap.gp.Primitive object at 0x00000254859256D8... <deap.gp.Terminal object at 0x0000025485A74F30>], [<deap.gp.Primitive object at 0x0000025485897278... <deap.gp.Terminal object at 0x0000025485A92708>], [<deap.gp.Primitive object at 0x0000025485925EF8... <deap.gp.Terminal object at 0x0000025485A79900>]], features=array([[1., 1., 1., ..., 0., 0., 0.],\n       [1...., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.]]), target=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), sample_weight=None, groups=None)\n   1167             chunk_size = min(cpu_count()*2, self.n_jobs*4)\n   1168             for chunk_idx in range(0, len(sklearn_pipeline_list), chunk_size):\n   1169                 self._stop_by_max_time_mins()\n   1170                 parallel = Parallel(n_jobs=self.n_jobs, verbose=0, pre_dispatch='2*n_jobs')\n   1171                 tmp_result_scores = parallel(delayed(partial_wrapped_cross_val_score)(sklearn_pipeline=sklearn_pipeline)\n-> 1172                                              for sklearn_pipeline in sklearn_pipeline_list[chunk_idx:chunk_idx + chunk_size])\n        sklearn_pipeline = undefined\n        sklearn_pipeline_list = [Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('decisiontree... random_state=42,\n            splitter='best'))]), Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('gradientboos...6000000000000001, verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('stackingesti... random_state=42,\n            splitter='best'))]), Pipeline(memory=None,\n     steps=[('zerocount', ... random_state=42, verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('rbfsampler',....3, verbose=0,\n              warm_start=False))]), Pipeline(memory=None, steps=[('gaussiannb', GaussianNB(priors=None))]), Pipeline(memory=None,\n     steps=[('stackingesti... random_state=42, verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('selectfwe', ...0.0001,\n          verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('decisiontree... random_state=42,\n            splitter='best'))]), Pipeline(memory=None,\n     steps=[('nystroem', N...nt=True,\n       subsample=0.35000000000000003))]), Pipeline(memory=None,\n     steps=[('linearsvc', ...y='l2', random_state=42, tol=0.001, verbose=0))]), Pipeline(memory=None,\n     steps=[('xgbclassifie...ent=True,\n       subsample=0.6500000000000001))]), Pipeline(memory=None,\n     steps=[('kneighborscl...ighbors=34, p=2,\n           weights='uniform'))]), Pipeline(memory=None,\n     steps=[('randomforest... random_state=42, verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('bernoullinb'...inarize=0.0, class_prior=None, fit_prior=True))]), Pipeline(memory=None,\n     steps=[('extratreescl... random_state=42, verbose=0, warm_start=False))]), Pipeline(memory=None,\n     steps=[('xgbclassifie...1, seed=42, silent=True,\n       subsample=1.0))]), Pipeline(memory=None,\n     steps=[('gradientboos...7500000000000001, verbose=0, warm_start=False))])]\n        chunk_idx = 0\n        chunk_size = 16\n   1173                 # update pbar\n   1174                 for val in tmp_result_scores:\n   1175                     result_score_list = self._update_val(val, result_score_list)\n   1176 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object TPOTBase._evaluate_individuals.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Mon Sep  3 16:19:12 2018\nPID: 3808                 Python 3.6.5: C:\\Users\\Admin\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300), (), {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = functools.partial(<function _wrapped_cross_val_s...c', sample_weight=None, groups=None, timeout=300)\n        args = ()\n        kwargs = {'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\stopit\\utils.py in wrapper(*args=(), **kwargs={'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)})\n    140             timeout = kwargs.pop(self.timeout_param, None)\n    141             if timeout:\n    142                 with self.to_ctx_mgr(timeout, swallow_exc=True):\n    143                     result = self.default  # noqa\n    144                     # ``result`` may not be assigned below in case of timeout\n--> 145                     result = func(*args, **kwargs)\n        result = 'Timeout'\n        args = ()\n        kwargs = {'cv': 5, 'features': memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), 'groups': None, 'sample_weight': None, 'scoring_function': 'roc_auc', 'sklearn_pipeline': Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), 'target': array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)}\n    146                 return result\n    147             else:\n    148                 return func(*args, **kwargs)\n    149         return wrapper\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tpot\\gp_deap.py in _wrapped_cross_val_score(sklearn_pipeline=Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))]), features=memmap([[1., 1., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 0., ..., 0., 0., 0.]]), target=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), cv=5, scoring_function='roc_auc', sample_weight=None, groups=None)\n    421     \"\"\"\n    422     sample_weight_dict = set_sample_weight(sklearn_pipeline.steps, sample_weight)\n    423 \n    424     features, target, groups = indexable(features, target, groups)\n    425 \n--> 426     cv = check_cv(cv, target, classifier=is_classifier(sklearn_pipeline))\n        cv = 5\n        target = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        sklearn_pipeline = Pipeline(memory=None,\n     steps=[('logisticregr...0.0001,\n          verbose=0, warm_start=False))])\n    427     cv_iter = list(cv.split(features, target, groups))\n    428     scorer = check_scoring(sklearn_pipeline, scoring=scoring_function)\n    429 \n    430     try:\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py in check_cv(cv=5, y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), classifier=True)\n   1900     if cv is None:\n   1901         cv = 3\n   1902 \n   1903     if isinstance(cv, numbers.Integral):\n   1904         if (classifier and (y is not None) and\n-> 1905                 (type_of_target(y) in ('binary', 'multiclass'))):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n   1906             return StratifiedKFold(cv)\n   1907         else:\n   1908             return KFold(cv)\n   1909 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py in type_of_target(y=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object))\n    283     # check float and contains non-integer float values\n    284     if y.dtype.kind == 'f' and np.any(y != y.astype(int)):\n    285         # [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\n    286         return 'continuous' + suffix\n    287 \n--> 288     if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n        y = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        y.ndim = 1\n    289         return 'multiclass' + suffix  # [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\n    290     else:\n    291         return 'binary'  # [1, 2] or [[\"a\"], [\"b\"]]\n    292 \n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in unique(ar=array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False, axis=None)\n    218     array([1, 2, 6, 4, 2, 3, 2])\n    219 \n    220     \"\"\"\n    221     ar = np.asanyarray(ar)\n    222     if axis is None:\n--> 223         return _unique1d(ar, return_index, return_inverse, return_counts)\n        ar = array(['ADNI', 'EMPL', nan, ..., 'EMPL', 'ADMI', nan], dtype=object)\n        return_index = False\n        return_inverse = False\n        return_counts = False\n    224     if not (-ar.ndim <= axis < ar.ndim):\n    225         raise ValueError('Invalid axis kwarg specified for unique')\n    226 \n    227     ar = np.swapaxes(ar, axis, 0)\n\n...........................................................................\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py in _unique1d(ar=array(['ADNI', nan, 'MEDI', ..., nan, 'EMPL', nan], dtype=object), return_index=False, return_inverse=False, return_counts=False)\n    278 \n    279     if optional_indices:\n    280         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n    281         aux = ar[perm]\n    282     else:\n--> 283         ar.sort()\n        ar.sort = <built-in method sort of numpy.ndarray object>\n    284         aux = ar\n    285     flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n    286 \n    287     if not optional_returns:\n\nTypeError: '<' not supported between instances of 'float' and 'str'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2da0da1324f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    648\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    639\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[1;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-56484b5ba9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the Classifier to take the training features and learn how they relate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# to the training y (the species)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
